{
    "id": "1498680",
    "text": "It\u00f4 integral Yt(B) () of a Brownian motion B () with respect to itself, i.e., both the integrand and the integrator are Brownian. It turns out Yt(B) = (B2 \\- t)/2. It\u00f4 calculus, named after Kiyoshi It\u00f4, extends the methods of calculus to stochastic processes such as Brownian motion (see Wiener process). It has important applications in mathematical finance and stochastic differential equations. The central concept is the It\u00f4 stochastic integral, a stochastic generalization of the Riemann\u2013Stieltjes integral in analysis. The integrands and the integrators are now stochastic processes: :Y_t=\\int_0^t H_s\\,dX_s, where H is a locally square-integrable process adapted to the filtration generated by X , which is a Brownian motion or, more generally, a semimartingale. The result of the integration is then another stochastic process. Concretely, the integral from 0 to any particular t is a random variable, defined as a limit of a certain sequence of random variables. The paths of Brownian motion fail to satisfy the requirements to be able to apply the standard techniques of calculus. So with the integrand a stochastic process, the It\u00f4 stochastic integral amounts to an integral with respect to a function which is not differentiable at any point and has infinite variation over every time interval. The main insight is that the integral can be defined as long as the integrand H is adapted, which loosely speaking means that its value at time t can only depend on information available up until this time. Roughly speaking, one chooses a sequence of partitions of the interval from 0 to t and construct Riemann sums. Every time we are computing a Riemann sum, we are using a particular instantiation of the integrator. It is crucial which point in each of the small intervals is used to compute the value of the function. The limit then is taken in probability as the mesh of the partition is going to zero. Numerous technical details have to be taken care of to show that this limit exists and is independent of the particular sequence of partitions. Typically, the left end of the interval is used. Important results of It\u00f4 calculus include the integration by parts formula and It\u00f4's lemma, which is a change of variables formula. These differ from the formulas of standard calculus, due to quadratic variation terms. In mathematical finance, the described evaluation strategy of the integral is conceptualized as that we are first deciding what to do, then observing the change in the prices. The integrand is how much stock we hold, the integrator represents the movement of the prices, and the integral is how much money we have in total including what our stock is worth, at any given moment. The prices of stocks and other traded financial assets can be modeled by stochastic processes such as Brownian motion or, more often, geometric Brownian motion (see Black\u2013Scholes). Then, the It\u00f4 stochastic integral represents the payoff of a continuous-time trading strategy consisting of holding an amount Ht of the stock at time t. In this situation, the condition that H is adapted corresponds to the necessary restriction that the trading strategy can only make use of the available information at any time. This prevents the possibility of unlimited gains through high-frequency trading: buying the stock just before each uptick in the market and selling before each downtick. Similarly, the condition that H is adapted implies that the stochastic integral will not diverge when calculated as a limit of Riemann sums . ==Notation== The process Y defined before as : Y_t = \\int_0^t H\\,dX\\equiv\\int_0^t H_s\\,dX_s , is itself a stochastic process with time parameter t, which is also sometimes written as Y = H \u00b7 X . Alternatively, the integral is often written in differential form dY = H dX, which is equivalent to Y \u2212 Y0 = H \u00b7 X. As It\u00f4 calculus is concerned with continuous-time stochastic processes, it is assumed that an underlying filtered probability space is given :(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\ge 0},\\mathbb{P}) . The \u03c3-algebra Ft represents the information available up until time t, and a process X is adapted if Xt is Ft-measurable. A Brownian motion B is understood to be an Ft-Brownian motion, which is just a standard Brownian motion with the properties that Bt is Ft-measurable and that Bt+s \u2212 Bt is independent of Ft for all s,t \u2265 0 . ==Integration with respect to Brownian motion== The It\u00f4 integral can be defined in a manner similar to the Riemann\u2013Stieltjes integral, that is as a limit in probability of Riemann sums; such a limit does not necessarily exist pathwise. Suppose that B is a Wiener process (Brownian motion) and that H is a right-continuous (c\u00e0dl\u00e0g), adapted and locally bounded process. If \\\\{\\pi_n\\\\} is a sequence of partitions of [0, t] with mesh going to zero, then the It\u00f4 integral of H with respect to B up to time t is a random variable :\\int_0^t H \\,d B =\\lim_{n\\rightarrow\\infty} \\sum_{[t_{i-1},t_i]\\in\\pi_n}H_{t_{i-1}}(B_{t_i}-B_{t_{i-1}}). It can be shown that this limit converges in probability. For some applications, such as martingale representation theorems and local times, the integral is needed for processes that are not continuous. The predictable processes form the smallest class that is closed under taking limits of sequences and contains all adapted left-continuous processes. If H is any predictable process such that \u222b0t H2 ds < \u221e for every t \u2265 0 then the integral of H with respect to B can be defined, and H is said to be B-integrable. Any such process can be approximated by a sequence Hn of left-continuous, adapted and locally bounded processes, in the sense that : \\int_0^t (H-H_n)^2\\,ds\\to 0 in probability. Then, the It\u00f4 integral is :\\int_0^t H\\,dB = \\lim_{n\\to\\infty}\\int_0^t H_n\\,dB where, again, the limit can be shown to converge in probability. The stochastic integral satisfies the It\u00f4 isometry :\\mathbb{E}\\left[ \\left(\\int_0^t H_s \\, dB_s\\right)^2\\right]=\\mathbb{E} \\left[ \\int_0^t H_s^2\\,ds\\right ] which holds when H is bounded or, more generally, when the integral on the right hand side is finite. ==It\u00f4 processes== Ricker wavelet. Off the tide of wavelet, the motion of It\u00f4 process is stable. An It\u00f4 process is defined to be an adapted stochastic process that can be expressed as the sum of an integral with respect to Brownian motion and an integral with respect to time, :X_t=X_0+\\int_0^t\\sigma_s\\,dB_s + \\int_0^t\\mu_s\\,ds. Here, B is a Brownian motion and it is required that \u03c3 is a predictable B-integrable process, and \u03bc is predictable and (Lebesgue) integrable. That is, :\\int_0^t(\\sigma_s^2+|\\mu_s|)\\,ds<\\infty for each t. The stochastic integral can be extended to such It\u00f4 processes, :\\int_0^t H\\,dX =\\int_0^t H_s\\sigma_s\\,dB_s + \\int_0^t H_s\\mu_s\\,ds. This is defined for all locally bounded and predictable integrands. More generally, it is required that H\u03c3 be B-integrable and H\u03bc be Lebesgue integrable, so that :\\int_0^t (H^2 \\sigma^2 + |H\\mu| )ds < \\infty. Such predictable processes H are called X-integrable. An important result for the study of It\u00f4 processes is It\u00f4's lemma. In its simplest form, for any twice continuously differentiable function f on the reals and It\u00f4 process X as described above, it states that f(X) is itself an It\u00f4 process satisfying :df(X_t)=f^\\prime(X_t)\\,dX_t + \\frac{1}{2}f^{\\prime\\prime} (X_t) \\sigma_t^2 \\, dt. This is the stochastic calculus version of the change of variables formula and chain rule. It differs from the standard result due to the additional term involving the second derivative of f, which comes from the property that Brownian motion has non- zero quadratic variation. ==Semimartingales as integrators== The It\u00f4 integral is defined with respect to a semimartingale X. These are processes which can be decomposed as X = M + A for a local martingale M and finite variation process A. Important examples of such processes include Brownian motion, which is a martingale, and L\u00e9vy processes. For a left continuous, locally bounded and adapted process H the integral H \u00b7 X exists, and can be calculated as a limit of Riemann sums. Let \u03c0n be a sequence of partitions of [0, t] with mesh going to zero, :\\int_0^t H\\,dX = \\lim_{n\\rightarrow\\infty} \\sum_{t_{i-1},t_i\\in\\pi_n}H_{t_{i-1}}(X_{t_i}-X_{t_{i-1}}). This limit converges in probability. The stochastic integral of left-continuous processes is general enough for studying much of stochastic calculus. For example, it is sufficient for applications of It\u00f4's Lemma, changes of measure via Girsanov's theorem, and for the study of stochastic differential equations. However, it is inadequate for other important topics such as martingale representation theorems and local times. The integral extends to all predictable and locally bounded integrands, in a unique way, such that the dominated convergence theorem holds. That is, if Hn \u2192 ;H and |Hn| \u2264 J for a locally bounded process J, then :\\int_0^t H_n dX \\to \\int_0^t H dX, in probability. The uniqueness of the extension from left-continuous to predictable integrands is a result of the monotone class lemma. In general, the stochastic integral H \u00b7 X can be defined even in cases where the predictable process H is not locally bounded. If K = 1 / (1 + |H|) then K and KH are bounded. Associativity of stochastic integration implies that H is X-integrable, with integral H \u00b7 X = Y, if and only if Y0 = 0 and K \u00b7 Y = (KH) \u00b7 X. The set of X-integrable processes is denoted by L(X). ==Properties== The following properties can be found in works such as and : * The stochastic integral is a c\u00e0dl\u00e0g process. Furthermore, it is a semimartingale. * The discontinuities of the stochastic integral are given by the jumps of the integrator multiplied by the integrand. The jump of a c\u00e0dl\u00e0g process at a time t is Xt \u2212 Xt\u2212, and is often denoted by \u0394Xt. With this notation, \u0394(H \u00b7 X) = H \u0394X. A particular consequence of this is that integrals with respect to a continuous process are always themselves continuous. * Associativity. Let J, K be predictable processes, and K be X-integrable. Then, J is K \u00b7 X integrable if and only if JK is X integrable, in which case *: J\\cdot (K\\cdot X) = (JK)\\cdot X * Dominated convergence. Suppose that Hn \u2192 H and |Hn| \u2264 J, where J is an X-integrable process. then Hn \u00b7 X \u2192 H \u00b7 X. Convergence is in probability at each time t. In fact, it converges uniformly on compacts in probability. * The stochastic integral commutes with the operation of taking quadratic covariations. If X and Y are semimartingales then any X-integrable process will also be [X, Y]-integrable, and [H \u00b7 X, Y] = H \u00b7 [X, Y]. A consequence of this is that the quadratic variation process of a stochastic integral is equal to an integral of a quadratic variation process, *:[H\\cdot X]=H^2\\cdot[X] ==Integration by parts== As with ordinary calculus, integration by parts is an important result in stochastic calculus. The integration by parts formula for the It\u00f4 integral differs from the standard result due to the inclusion of a quadratic covariation term. This term comes from the fact that It\u00f4 calculus deals with processes with non-zero quadratic variation, which only occurs for infinite variation processes (such as Brownian motion). If X and Y are semimartingales then :X_tY_t = X_0Y_0+\\int_0^t X_{s-}\\,dY_s + \\int_0^t Y_{s-}\\,dX_s + [X,Y]_t where [X, Y] is the quadratic covariation process. The result is similar to the integration by parts theorem for the Riemann\u2013Stieltjes integral but has an additional quadratic variation term. ==It\u00f4's lemma== It\u00f4's lemma is the version of the chain rule or change of variables formula which applies to the It\u00f4 integral. It is one of the most powerful and frequently used theorems in stochastic calculus. For a continuous n-dimensional semimartingale X = (X1,...,Xn) and twice continuously differentiable function f from Rn to R, it states that f(X) is a semimartingale and, :df(X_t)= \\sum_{i=1}^n f_{i}(X_t)\\,dX^i_t + \\frac{1}{2}\\sum_{i,j=1}^n f_{i,j}(X_{t})\\,d[X^i,X^j]_t. This differs from the chain rule used in standard calculus due to the term involving the quadratic covariation [Xi,Xj ]. The formula can be generalized to non-continuous semimartingales by adding a pure jump term to ensure that the jumps of the left and right hand sides agree (see It\u00f4's lemma). ==Martingale integrators== ===Local martingales=== An important property of the It\u00f4 integral is that it preserves the local martingale property. If M is a local martingale and H is a locally bounded predictable process then H \u00b7 M is also a local martingale. For integrands which are not locally bounded, there are examples where H \u00b7 M is not a local martingale. However, this can only occur when M is not continuous. If M is a continuous local martingale then a predictable process H is M-integrable if and only if :\\int_0^t H^2 d[M] <\\infty, for each t, and H \u00b7 M is always a local martingale. The most general statement for a discontinuous local martingale M is that if (H2 \u00b7 [M])1/2 is locally integrable then H \u00b7 M exists and is a local martingale. ===Square integrable martingales=== For bounded integrands, the It\u00f4 stochastic integral preserves the space of square integrable martingales, which is the set of c\u00e0dl\u00e0g martingales M such that E[Mt2] is finite for all t. For any such square integrable martingale M, the quadratic variation process [M] is integrable, and the It\u00f4 isometry states that :\\mathbb{E}\\left [(H\\cdot M_t)^2\\right ]=\\mathbb{E}\\left [\\int_0^t H^2\\,d[M]\\right ]. This equality holds more generally for any martingale M such that H2 \u00b7 [M]t is integrable. The It\u00f4 isometry is often used as an important step in the construction of the stochastic integral, by defining H \u00b7 M to be the unique extension of this isometry from a certain class of simple integrands to all bounded and predictable processes. ===p-Integrable martingales=== For any p > 1, and bounded predictable integrand, the stochastic integral preserves the space of p-integrable martingales. These are c\u00e0dl\u00e0g martingales such that E(|Mt|p) is finite for all t. However, this is not always true in the case where p = 1\\. There are examples of integrals of bounded predictable processes with respect to martingales which are not themselves martingales. The maximum process of a c\u00e0dl\u00e0g process M is written as M*t = sups \u2264t |Ms|. For any p \u2265 1 and bounded predictable integrand, the stochastic integral preserves the space of c\u00e0dl\u00e0g martingales M such that E[(M*t)p] is finite for all t. If p > 1 then this is the same as the space of p-integrable martingales, by Doob's inequalities. The Burkholder\u2013Davis\u2013Gundy inequalities state that, for any given p \u2265 1, there exist positive constants c, C that depend on p, but not M or on t such that :c\\mathbb{E} \\left [ [M]_t^{\\frac{p}{2}} \\right ] \\le \\mathbb{E}\\left [(M^*_t)^p \\right ]\\le C\\mathbb{E}\\left [ [M]_t^{\\frac{p}{2}} \\right ] for all c\u00e0dl\u00e0g local martingales M. These are used to show that if (M*t)p is integrable and H is a bounded predictable process then :\\mathbb{E}\\left [ ((H\\cdot M)_t^*)^p \\right ] \\le C\\mathbb{E}\\left [(H^2\\cdot[M]_t)^{\\frac{p}{2}} \\right ]<\\infty and, consequently, H \u00b7 M is a p-integrable martingale. More generally, this statement is true whenever (H2 \u00b7 [M])p/2 is integrable. ==Existence of the integral== Proofs that the It\u00f4 integral is well defined typically proceed by first looking at very simple integrands, such as piecewise constant, left continuous and adapted processes where the integral can be written explicitly. Such simple predictable processes are linear combinations of terms of the form Ht = A1{t > T} for stopping times T and FT-measurable random variables A, for which the integral is :H\\cdot X_t\\equiv \\mathbf{1}_{\\\\{t>T\\\\}}A(X_t-X_T). This is extended to all simple predictable processes by the linearity of H \u00b7 X in H. For a Brownian motion B, the property that it has independent increments with zero mean and variance Var(Bt) = t can be used to prove the It\u00f4 isometry for simple predictable integrands, : \\mathbb{E} \\left [ (H\\cdot B_t)^2\\right ] = \\mathbb{E} \\left [\\int_0^tH_s^2\\,ds\\right ]. By a continuous linear extension, the integral extends uniquely to all predictable integrands satisfying : \\mathbb{E} \\left[ \\int_0^t H^2 ds \\right ] < \\infty, in such way that the It\u00f4 isometry still holds. It can then be extended to all B-integrable processes by localization. This method allows the integral to be defined with respect to any It\u00f4 process. For a general semimartingale X, the decomposition X = M + A into a local martingale M plus a finite variation process A can be used. Then, the integral can be shown to exist separately with respect to M and A and combined using linearity, H \u00b7 X = H \u00b7 M + H \u00b7 A, to get the integral with respect to X. The standard Lebesgue\u2013Stieltjes integral allows integration to be defined with respect to finite variation processes, so the existence of the It\u00f4 integral for semimartingales will follow from any construction for local martingales. For a c\u00e0dl\u00e0g square integrable martingale M, a generalized form of the It\u00f4 isometry can be used. First, the Doob\u2013Meyer decomposition theorem is used to show that a decomposition M2 = N + exists, where N is a martingale and is a right-continuous, increasing and predictable process starting at zero. This uniquely defines , which is referred to as the predictable quadratic variation of M. The It\u00f4 isometry for square integrable martingales is then :\\mathbb{E} \\left [(H\\cdot M_t)^2\\right ]= \\mathbb{E} \\left [\\int_0^tH^2_s\\,d\\langle M\\rangle_s\\right], which can be proved directly for simple predictable integrands. As with the case above for Brownian motion, a continuous linear extension can be used to uniquely extend to all predictable integrands satisfying E[H2 \u00b7 t] < \u221e. This method can be extended to all local square integrable martingales by localization. Finally, the Doob\u2013Meyer decomposition can be used to decompose any local martingale into the sum of a local square integrable martingale and a finite variation process, allowing the It\u00f4 integral to be constructed with respect to any semimartingale. Many other proofs exist which apply similar methods but which avoid the need to use the Doob\u2013Meyer decomposition theorem, such as the use of the quadratic variation [M] in the It\u00f4 isometry, the use of the Dol\u00e9ans measure for submartingales, or the use of the Burkholder\u2013Davis\u2013Gundy inequalities instead of the It\u00f4 isometry. The latter applies directly to local martingales without having to first deal with the square integrable martingale case. Alternative proofs exist only making use of the fact that X is c\u00e0dl\u00e0g, adapted, and the set {H \u00b7 Xt: |H| \u2264 1 is simple previsible} is bounded in probability for each time t, which is an alternative definition for X to be a semimartingale. A continuous linear extension can be used to construct the integral for all left-continuous and adapted integrands with right limits everywhere (caglad or L-processes). This is general enough to be able to apply techniques such as It\u00f4's lemma . Also, a Khintchine inequality can be used to prove the dominated convergence theorem and extend the integral to general predictable integrands . ==Differentiation in It\u00f4 calculus== The It\u00f4 calculus is first and foremost defined as an integral calculus as outlined above. However, there are also different notions of \"derivative\" with respect to Brownian motion: ===Malliavin derivative=== Malliavin calculus provides a theory of differentiation for random variables defined over Wiener space, including an integration by parts formula . ===Martingale representation=== The following result allows to express martingales as It\u00f4 integrals: if M is a square- integrable martingale on a time interval [0, T] with respect to the filtration generated by a Brownian motion B, then there is a unique adapted square integrable process \u03b1 on [0, T] such that :M_{t} = M_{0} + \\int_{0}^{t} \\alpha_{s} \\, \\mathrm{d} B_{s} almost surely, and for all t \u2208 [0, T] . This representation theorem can be interpreted formally as saying that \u03b1 is the \"time derivative\" of M with respect to Brownian motion B, since \u03b1 is precisely the process that must be integrated up to time t to obtain Mt \u2212 M0, as in deterministic calculus. ==It\u00f4 calculus for physicists== In physics, usually stochastic differential equations (SDEs), such as Langevin equations, are used, rather than stochastic integrals. Here an It\u00f4 stochastic differential equation (SDE) is often formulated via : \\dot{x}_k=h_k+g_{kl} \\xi_l, where \\xi_j is Gaussian white noise with :\\langle\\xi_k(t_1)\\,\\xi_l(t_2)\\rangle=\\delta_{kl}\\delta(t_1-t_2) and Einstein's summation convention is used. If y=y(x_k) is a function of the xk, then It\u00f4's lemma has to be used: : \\dot{y}=\\frac{\\partial y}{\\partial x_j}\\dot{x}_j+\\frac{1}{2}\\frac{\\partial^2 y}{\\partial x_k \\, \\partial x_l} g_{km}g_{ml}. An It\u00f4 SDE as above also corresponds to a Stratonovich SDE which reads : \\dot{x}_k = h_k + g_{kl} \\xi_l - \\frac{1}{2} \\frac{\\partial g_{kl}}{\\partial {x_m}} g_{ml}. SDEs frequently occur in physics in Stratonovich form, as limits of stochastic differential equations driven by colored noise if the correlation time of the noise term approaches zero. For a recent treatment of different interpretations of stochastic differential equations see for example . == It\u00f4 interpretation and supersymmetric theory of SDEs == In the supersymmetric theory of SDEs, stochastic evolution is defined via stochastic evolution operator (SEO) acting on differential forms of the phase space. The It\u00f4-Stratonovich dilemma takes the form of the ambiguity of the operator ordering that arises on the way from the path integral to the operator representation of stochastic evolution. The It\u00f4 interpretation corresponds to the operator ordering convention that all the momentum operators act after all the position operators. The SEO can be made unique by supplying it with its most natural mathematical definition of the pullback induced by the noise-configuration-dependent SDE-defined diffeomorphisms and averaged over the noise configurations. This disambiguation leads to the Stratonovich interpretation of SDEs that can be turned into the It\u00f4 interpretation by a specific shift of the flow vector field of the SDE. ==See also== *Stochastic calculus *Wiener process *It\u00f4's lemma *Stratonovich integral *Semimartingale ==References== * * *Hagen Kleinert (2004). Path Integrals in Quantum Mechanics, Statistics, Polymer Physics, and Financial Markets, 4th edition, World Scientific (Singapore); Paperback . Fifth edition available online: PDF-files, with generalizations of It\u00f4's lemma for non- Gaussian processes. * * * * * * * * * Mathematical Finance Programming in TI- Basic, which implements Ito calculus for TI-calculators. Category:Definitions of mathematical integration Category:Stochastic calculus ",
    "title": "It\u00f4 calculus"
}