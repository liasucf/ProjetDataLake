{
    "id": "56649828",
    "text": "openSMILEF. Eyben, M. W\u00f6llmer, B. Schuller: \u201eopenSMILE - The Munich Versatile and Fast Open-Source Audio Feature Extractor\u201c, In Proc. ACM Multimedia (MM), ACM, Florence, Italy, ACM, pp. 1459-1462, October 2010. is source-available software for automatic extraction of features from audio signals and for classification of speech and music signals. \"SMILE\" stands for \"Speech & Music Interpretation by Large-space Extraction\". The software is mainly applied in the area of automatic emotion recognition and is widely used in the affective computing research community. The openSMILE project exists since 2008 and is maintained by the German company audEERING GmbH since 2013. openSMILE is provided free of charge for research purposes and personal use under a source- available license. For commercial use of the tool, the company audEERING offers custom license options. == Application Areas == openSMILE is used for academic research as well as for commercial applications in order to automatically analyze speech and music signals in real-time. In contrast to automatic speech recognition which extracts the spoken content out of a speech signal, openSMILE is capable of recognizing the characteristics of a given speech or music segment. Examples for such characteristics encoded in human speech are a speaker's emotionB. Schuller, B. Vlasenko, F. Eyben, M. W\u00f6llmer, A. Stuhlsatz, A. Wendemuth, G. Rigoll, \"Cross-Corpus Acoustic Emotion Recognition: Variances and Strategies (Extended Abstract),\" in Proc. of ACII 2015, Xi'an, China, invited for the Special Session on Most Influential Articles in IEEE Transactions on Affective Computing., age, gender, and personality, as well as speaker states like depression, intoxication, or vocal pathological disorders. The software further includes music classification technology for automatic music mood detection and recognition of chorus segments, key, chords, tempo, meter, dance-style, and genre. The openSMILE toolkit serves as benchmark in manifold research competitions such as Interspeech ComParEB. Schuller, S. Steidl, A. Batliner, J. Hirschberg, J. K. Burgoon, A. Elkins, Y. Zhang, E. Coutinho: \"The INTERSPEECH 2016 Computational Paralinguistics Challenge: Deception & Sincerity \", Proceedings INTERSPEECH 2016, ISCA, San Francisco, USA, 2016., AVECF. Ringeval, B. Schuller, M. Valstar, R. Cowie, M. Pantic, \u201cAVEC 2015 - The 5th International Audio/Visual Emotion Challenge and Workshop,\u201d in Proceedings of the 23rd ACM International Conference on Multimedia, MM 2015, (Brisbane, Australia), ACM, October 2015., MediaEvalM. Eskevich, R. Aly, D. Racca, R. Ordelman, S. Chen, G. J. Jones, \"The search and hyperlinking task at MediaEval 2014\"., and EmotiWF. Ringeval, S. Amiriparian, F. Eyben, K. Scherer, B. Schuller, \u201cEmotion Recognition in the Wild: Incorporating Voice and Lip Activity in Multimodal Decision-Level Fusion,\u201d in Proceedings of the ICMI 2014 EmotiW \u2013 Emotion Recognition In The Wild Challenge and Workshop (EmotiW 2014), Satellite of the 16th ACM International Conference on Multimodal Interaction (ICMI 2014), (Istanbul, Turkey), pp. 473\u2013 480, ACM, November 2014. == History == The openSMILE project was started in 2008 by Florian Eyben, Martin W\u00f6llmer, and Bj\u00f6rn Schuller at the Technical University of Munich within the European Union research project SEMAINE. The goal of the SEMAINE project was to develop a virtual agent with emotional and social intelligence. In this system, openSMILE was applied for real-time analysis of speech and emotion. The final SEMAINE software release is based on openSMILE version 1.0.1. In 2009, the emotion recognition toolkit (openEAR) was published based on openSMILE. \"EAR\" stands for \"Emotion and Affect Recognition\". In 2010, openSMILE version 1.0.1 was published and was introduced and awarded at the ACM Multimedia Open-Source Software Challenge. Between 2011 and 2013, the technology of openSMILE was extended and improved by Florian Eyben and Felix Weninger in the context of their doctoral thesis at the Technical University of Munich. The software was also applied for the project ASC-Inclusion, which was funded by the European Union. For this project, the software was extended by Erik Marchi in order to teach emotional expression to autistic children, based on automatic emotion recognition and visualization. In 2013, the company audEERING acquired the rights to the code- base from the Technical University of Munich and version 2.0 was published under a source-available research license. Until 2016, openSMILE was downloaded more than 50,000 times worldwide and has established itself as a standard toolkit for emotion recognition. == Awards == openSMILE was awarded in 2010 in the context of the ACM Multimedia Open Source Competition. The software tool is applied in numerous scientific publications on automatic emotion recognition. openSMILE and its extension openEAR have been cited in more than 1000 scientific publications until today. == References == == Weblinks == * openSMILE website * openSMILE book * Google Scholar page on openSMILE * Google Scholar page on openEAR * Article on startupvalley.com Category:Audio software Category:Affective computing ",
    "title": "OpenSMILE"
}