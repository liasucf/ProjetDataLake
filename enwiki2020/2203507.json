{
    "id": "2203507",
    "text": "In computer science, future, promise, delay, and deferred refer to constructs used for synchronizing program execution in some concurrent programming languages. They describe an object that acts as a proxy for a result that is initially unknown, usually because the computation of its value is not yet complete. The term promise was proposed in 1976 by Daniel P. Friedman and David Wise, and Peter Hibbard called it eventual. A somewhat similar concept future was introduced in 1977 in a paper by Henry Baker and Carl Hewitt. The terms future, promise, delay, and deferred are often used interchangeably, although some differences in usage between future and promise are treated below. Specifically, when usage is distinguished, a future is a read-only placeholder view of a variable, while a promise is a writable, single assignment container which sets the value of the future. Notably, a future may be defined without specifying which specific promise will set its value, and different possible promises may set the value of a given future, though this can be done only once for a given future. In other cases a future and a promise are created together and associated with each other: the future is the value, the promise is the function that sets the value \u2013 essentially the return value (future) of an asynchronous function (promise). Setting the value of a future is also called resolving, fulfilling, or binding it. ==Applications== Futures and promises originated in functional programming and related paradigms (such as logic programming) to decouple a value (a future) from how it was computed (a promise), allowing the computation to be done more flexibly, notably by parallelizing it. Later, it found use in distributed computing, in reducing the latency from communication round trips. Later still, it gained more use by allowing writing asynchronous programs in direct style, rather than in continuation-passing style. ==Implicit vs. explicit== Use of futures may be implicit (any use of the future automatically obtains its value, as if it were an ordinary reference) or explicit (the user must call a function to obtain the value, such as the `get` method of in Java). Obtaining the value of an explicit future can be called stinging or forcing. Explicit futures can be implemented as a library, whereas implicit futures are usually implemented as part of the language. The original Baker and Hewitt paper described implicit futures, which are naturally supported in the actor model of computation and pure object-oriented programming languages like Smalltalk. The Friedman and Wise paper described only explicit futures, probably reflecting the difficulty of efficiently implementing implicit futures on stock hardware. The difficulty is that stock hardware does not deal with futures for primitive data types like integers. For example, an add instruction does not know how to deal with `3 + future factorial(100000)`. In pure actor or object languages this problem can be solved by sending `future factorial(100000)` the message `+[3]`, which asks the future to add `3` to itself and return the result. Note that the message passing approach works regardless of when `factorial(100000)` finishes computation and that no stinging/forcing is needed. ==Promise pipelining== The use of futures can dramatically reduce latency in distributed systems. For instance, futures enable promise pipelining,Promise Pipelining at erights.orgPromise Pipelining on the C2 wiki as implemented in the languages E and Joule, which was also called call-stream Also published in ACM SIGPLAN Notices 23(7). in the language Argus. Consider an expression involving conventional remote procedure calls, such as: t3 := ( x.a() ).c( y.b() ) which could be expanded to t1 := x.a(); t2 := y.b(); t3 := t1.c(t2); Each statement needs a message to be sent and a reply received before the next statement can proceed. Suppose, for example, that `x`, `y`, `t1`, and `t2` are all located on the same remote machine. In this case, two complete network round-trips to that machine must take place before the third statement can begin to execute. The third statement will then cause yet another round-trip to the same remote machine. Using futures, the above expression could be written t3 := (x <- a()) <- c(y <- b()) which could be expanded to t1 := x <- a(); t2 := y <- b(); t3 := t1 <- c(t2); The syntax used here is that of the language E, where `x <- a()` means to send the message `a()` asynchronously to `x`. All three variables are immediately assigned futures for their results, and execution proceeds to subsequent statements. Later attempts to resolve the value of `t3` may cause a delay; however, pipelining can reduce the number of round-trips needed. If, as in the prior example, `x`, `y`, `t1`, and `t2` are all located on the same remote machine, a pipelined implementation can compute `t3` with one round-trip instead of three. Because all three messages are destined for objects which are on the same remote machine, only one request need be sent and only one response need be received containing the result. The send `t1 <- c(t2)` would not block even if `t1` and `t2` were on different machines to each other, or to `x` or `y`. Promise pipelining should be distinguished from parallel asynchronous message passing. In a system supporting parallel message passing but not pipelining, the message sends `x <- a()` and `y <- b()` in the above example could proceed in parallel, but the send of `t1 <- c(t2)` would have to wait until both `t1` and `t2` had been received, even when `x`, `y`, `t1`, and `t2` are on the same remote machine. The relative latency advantage of pipelining becomes even greater in more complicated situations involving many messages. Promise pipelining also should not be confused with pipelined message processing in actor systems, where it is possible for an actor to specify and begin executing a behaviour for the next message before having completed processing of the current message. ==Read-only views== In some programming languages such as Oz, E, and AmbientTalk, it is possible to obtain a read-only view of a future, which allows reading its value when resolved, but does not permit resolving it: * In Oz, the `!!` operator is used to obtain a read-only view. * In E and AmbientTalk, a future is represented by a pair of values called a promise/resolver pair. The promise represents the read-only view, and the resolver is needed to set the future's value. * In C++11 a `std::future` provides a read-only view. The value is set directly by using a `std::promise`, or set to the result of a function call using `std::packaged_task` or `std::async`. * In the Dojo Toolkit's Deferred API as of version 1.5, a consumer-only promise object represents a read-only view. * In Alice ML, futures provide a read-only view, whereas a promise contains both a future and the ability to resolve the future * In .NET 4.0 `System.Threading.Tasks.Task` represents a read-only view. Resolving the value can be done via `System.Threading.Tasks.TaskCompletionSource`. Support for read-only views is consistent with the principle of least privilege, since it enables the ability to set the value to be restricted to subjects that need to set it. In a system that also supports pipelining, the sender of an asynchronous message (with result) receives the read-only promise for the result, and the target of the message receives the resolver. ==Thread-specific futures== Some languages, such as Alice ML, define futures that are associated with a specific thread that computes the future's value. This computation can start either eagerly when the future is created, or lazily when its value is first needed. A lazy future is similar to a thunk, in the sense of a delayed computation. Alice ML also supports futures that can be resolved by any thread, and calls these promises. This use of promise is different from its use in E as described above. In Alice, a promise is not a read-only view, and promise pipelining is unsupported. Instead, pipelining naturally happens for futures, including ones associated with promises. ==Blocking vs non-blocking semantics== If the value of a future is accessed asynchronously, for example by sending a message to it, or by explicitly waiting for it using a construct such as `when` in E, then there is no difficulty in delaying until the future is resolved before the message can be received or the wait completes. This is the only case to be considered in purely asynchronous systems such as pure actor languages. However, in some systems it may also be possible to attempt to immediately or synchronously access a future's value. Then there is a design choice to be made: * the access could block the current thread or process until the future is resolved (possibly with a timeout). This is the semantics of dataflow variables in the language Oz. * the attempted synchronous access could always signal an error, for example throwing an exception. This is the semantics of remote promises in E. * potentially, the access could succeed if the future is already resolved, but signal an error if it is not. This would have the disadvantage of introducing nondeterminism and the potential for race conditions, and seems to be an uncommon design choice. As an example of the first possibility, in C++11, a thread that needs the value of a future can block until it is available by calling the `wait()` or `get()` member functions. You can also specify a timeout on the wait using the `wait_for()` or `wait_until()` member functions to avoid indefinite blocking. If the future arose from a call to `std::async` then a blocking wait (without a timeout) may cause synchronous invocation of the function to compute the result on the waiting thread. ==Related constructs== Future is a particular case of Event (synchronization primitive), which can be completed only once. In general, events can be reset to initial empty state and, thus, completed as many times as you like.500 lines or less, \"A Web Crawler With asyncio Coroutines\" by A. Jesse Jiryu Davis and Guido van Rossum says \"implementation uses an asyncio.Event in place of the Future shown here. The difference is an Event can be reset, whereas a Future cannot transition from resolved back to pending.\" An I-var (as in the language Id) is a future with blocking semantics as defined above. An I-structure is a data structure containing I-vars. A related synchronization construct that can be set multiple times with different values is called an M-var. M-vars support atomic operations to take or put the current value, where taking the value also sets the M-var back to its initial empty state. A concurrent logic variable is similar to a future, but is updated by unification, in the same way as logic variables in logic programming. Thus it can be bound more than once to unifiable values, but cannot be set back to an empty or unresolved state. The dataflow variables of Oz act as concurrent logic variables, and also have blocking semantics as mentioned above. A concurrent constraint variable is a generalization of concurrent logic variables to support constraint logic programming: the constraint may be narrowed multiple times, indicating smaller sets of possible values. Typically there is a way to specify a thunk that should run whenever the constraint is narrowed further; this is needed to support constraint propagation. ==Relations between the expressiveness of different forms of future== Eager thread-specific futures can be straightforwardly implemented in non-thread-specific futures, by creating a thread to calculate the value at the same time as creating the future. In this case it is desirable to return a read-only view to the client, so that only the newly created thread is able to resolve this future. To implement implicit lazy thread-specific futures (as provided by Alice ML, for example) in terms in non-thread-specific futures, needs a mechanism to determine when the future's value is first needed (for example, the `WaitNeeded` construct in Oz). If all values are objects, then the ability to implement transparent forwarding objects is sufficient, since the first message sent to the forwarder indicates that the future's value is needed. Non-thread-specific futures can be implemented in thread-specific futures, assuming that the system supports message passing, by having the resolving thread send a message to the future's own thread. However, this can be viewed as unneeded complexity. In programming languages based on threads, the most expressive approach seems to be to provide a mix of non-thread- specific futures, read-only views, and either a WaitNeeded construct, or support for transparent forwarding. ==Evaluation strategy== The evaluation strategy of futures, which may be termed call by future, is non-deterministic: the value of a future will be evaluated at some time between when the future is created and when its value is used, but the precise time is not determined beforehand and can change from run to run. The computation can start as soon as the future is created (eager evaluation) or only when the value is actually needed (lazy evaluation), and may be suspended part-way through, or executed in one run. Once the value of a future is assigned, it is not recomputed on future accesses; this is like the memoization used in call by need. A ' is a future that deterministically has lazy evaluation semantics: the computation of the future's value starts when the value is first needed, as in call by need. Lazy futures are of use in languages which evaluation strategy is by default not lazy. For example, in C++11 such lazy futures can be created by passing the `std::launch::deferred` launch policy to `std::async`, along with the function to compute the value. ==Semantics of futures in the actor model== In the actor model, an expression of the form `future ` is defined by how it responds to an `Eval` message with environment E and customer C as follows: The future expression responds to the `Eval` message by sending the customer C a newly created actor F (the proxy for the response of evaluating ``) as a return value concurrently with sending `` an `Eval` message with environment E and customer C. The default behavior of F is as follows: * When F receives a request R, then it checks to see if it has already received a response (that can either be a return value or a thrown exception) from evaluating `` proceeding as follows: *# If it already has a response V, then *#*If V is a return value, then it is sent the request R. *#*If V is an exception, then it is thrown to the customer of the request R. *# If it does not already have a response, then R is stored in the queue of requests inside the F. * When F receives the response V from evaluating ``, then V is stored in F and **If V is a return value, then all of the queued requests are sent to V. **If V is an exception, then it is thrown to the customer of each of the queued requests. However, some futures can deal with requests in special ways to provide greater parallelism. For example, the expression `1 + future factorial(n)` can create a new future that will behave like the number `1+factorial(n)`. This trick does not always work. For example, the following conditional expression: : `if m>future factorial(n) then print(\"bigger\") else print(\"smaller\")` suspends until the future for `factorial(n)` has responded to the request asking if `m` is greater than itself. ==History== The future and/or promise constructs were first implemented in programming languages such as MultiLisp and Act 1. The use of logic variables for communication in concurrent logic programming languages was quite similar to futures. These began in Prolog with Freeze and IC Prolog, and became a true concurrency primitive with Relational Language, Concurrent Prolog, guarded Horn clauses (GHC), Parlog, Strand, Vulcan, Janus, Oz-Mozart, Flow Java, and Alice ML. The single-assignment I-var from dataflow programming languages, originating in Id and included in Reppy's Concurrent ML, is much like the concurrent logic variable. The promise pipelining technique (using futures to overcome latency) was invented by Barbara Liskov and Liuba Shrira in 1988, and independently by Mark S. Miller, Dean Tribble and Rob Jellinghaus in the context of Project Xanadu circa 1989. The term promise was coined by Liskov and Shrira, although they referred to the pipelining mechanism by the name call-stream, which is now rarely used. Both the design described in Liskov and Shrira's paper, and the implementation of promise pipelining in Xanadu, had the limit that promise values were not first-class: an argument to, or the value returned by a call or send could not directly be a promise (so the example of promise pipelining given earlier, which uses a promise for the result of one send as an argument to another, would not have been directly expressible in the call-stream design or in the Xanadu implementation). It seems that promises and call-streams were never implemented in any public release of Argus, the programming language used in the Liskov and Shrira paper. Argus development stopped around 1988. The Xanadu implementation of promise pipelining only became publicly available with the release of the source code for Udanax Gold in 1999, and was never explained in any published document. The later implementations in Joule and E support fully first-class promises and resolvers. Several early actor languages, including the Act series, supported both parallel message passing and pipelined message processing, but not promise pipelining. (Although it is technically possible to implement the last of these features in the first two, there is no evidence that the Act languages did so.) After 2000, a major revival of interest in futures and promises occurred, due to their use in responsiveness of user interfaces, and in web development, due to the request\u2013response model of message-passing. Several mainstream languages now have language support for futures and promises, most notably popularized by `FutureTask` in Java 5 (announced 2004) and the `async` and `await` constructions in .NET 4.5 (announced 2010, released 2012) largely inspired by the asynchronous workflows of F#, which dates to 2007. This has subsequently been adopted by other languages, notably Dart (2014), Python (2015), Hack (HHVM), and drafts of ECMAScript 7 (JavaScript), Scala, and C++. ==List of implementations== Some programming languages are supporting futures, promises, concurrent logic variables, dataflow variables, or I-vars, either by direct language support or in the standard library. ===List of concepts related to futures and promises by programming language=== * ABCL/f * Alice ML * AmbientTalk (including first- class resolvers and read-only promises) * C++, starting with C++11: std::future and std::promise ** \u03bcC++ ** Compositional C++ * Crystal (programming language) * Dart (with Future/Completer classes and the keywords await and async) * Elm (programming language) via the Task module * Glasgow Haskell (I-vars and M-vars only) * Id (I-vars and M-vars only) * Io * Java via or ** Flow Java * JavaScript (limited, as of ECMAScript 6) * Lucid (dataflow only) * Some Lisps ** Clojure ** MultiLisp * .NET via Tasks ** C#, since .NET Framework 4.5, via the keywords `async` and `await` * Nim * Oxygene * Oz version 3 * Python concurrent.futures, since 3.2,Python 3.2 Release as proposed by the PEP 3148, and Python 3.5 added async and awaitPython 3.5 Release * R (promises for lazy evaluation, still single threaded) * Racket * RakuPromise class in Perl 6 * Scala via scala.concurrent package * Scheme * Squeak Smalltalk * Strand * Swift (only via third-party libraries) * Visual Basic 11 (via the keywords Async and Await) Languages also supporting promise pipelining include: * E * Joule ===List of non-standard, library based implementations of futures=== * For Common Lisp: ** BlackbirdCommon Lisp Blackbird ** Eager Future2Common Lisp Eager Future2 ** lparallelLisp in parallel \u2013 A parallel programming library for Common Lisp ** PCallCommon Lisp PCall * For C++: ** Boost library ** Dlib ** Qt ** Seastar ** Folly ** POCO C++ Libraries (Active Results) ** HPX * For C# and other .NET languages: The Parallel Extensions library * For Groovy: GParsGroovy GPars * For JavaScript: ** Cujo.js'Cujo.js when.jsJavaScript when.js provides promises conforming to the Promises/A+Promises/A+ specification 1.1 specification ** The Dojo Toolkit supplies promisespromises and Twisted style deferreds ** MochiKitJavaScript MochKit.Async inspired by Twisted's Deferreds ** jQuery's Deferred Object is based on the CommonJS Promises/A design. ** AngularJSJavaScript Angularjs ** node-promiseJavaScript node-promise ** Q, by Kris Kowal, conforms to Promises/A+ 1.1JavaScript Q ** RSVP.js, conforms to Promises/A+ 1.1JavaScript RSVP.js ** YUI'sYUI JavaScript class library promise classYUI JavaScript promise class conforms to the Promises/A+ 1.0 specification. ** Bluebird, by Petka AntonovJavaScript Bluebird ** The Closure Library's promise package conforms to the Promises/A+ specification. ** See Promise/A+'s list for more implementations based on the Promise/A+ design. * For Java: ** JDeferred, provides deferred-promise API and behavior similar to JQuery.Deferred objectJava JDeferred ** ParSeqJava ParSeq provides task-promise API ideal for asynchronous pipelining and branching, maintained by LinkedIn * For Lua: ** The cqueues module contains a Promise API. * For Objective-C: MAFuture,Objective-C MAFuture GitHubObjective-C MAFuture mikeash.com RXPromise,Objective-C RXPromise ObjC-CollapsingFutures,ObjC-CollapsingFutures PromiseKit,Objective-C PromiseKit objc-promise,Objective-C objc-promise OAPromise,Objective-C OAPromise * For OCaml: Lazy module implements lazy explicit futuresOCaml Lazy * For Perl: Future,Perl Future Promises,Perl Promises Reflex,Perl Reflex and Promise::ES6Perl Promise::ES6 * For PHP: React/PromisePHP React/Promise * For Python: ** Built-in implementationPython built-in implementation ** pythonfuturespythonfutures ** Twisted's DeferredsTwisted Deferreds * For R: ** future, implements an extendable future API with lazy and eager synchronous and (multicore or distributed) asynchronous futuresR package futurefuture * For Ruby: ** Promise gemRuby Promise gem ** libuv gem, implements promisesRuby libuv ** Celluloid gem, implements futuresRuby Celluloid gem ** future-resourceRuby future-resource * For Rust: ** futures-rsfutures-rs crate * For Scala: ** Twitter's util libraryTwitter's util library * For Swift: ** Async framework, implements C#-style `async`/non-blocking `await`Swift Async ** FutureKit,Swift FutureKit implements a version for Apple GCDSwift Apple GCD ** FutureLib, pure Swift 2 library implementing Scala-style futures and promises with TPL-style cancellationSwift FutureLib ** Deferred, pure Swift library inspired by OCaml's Deferredbignerdranch/Deferred ** BrightFuturesThomvis/BrightFutures * For Tcl: tcl-promisetcl-promise ===Coroutines=== Futures can be implemented in coroutines or generators,Does async/await solve a real problem? resulting in the same evaluation strategy (e.g., cooperative multitasking or lazy evaluation). ===Channels=== Futures can easily be implemented in channels: a future is a one-element channel, and a promise is a process that sends to the channel, fulfilling the future.Go language patterns FuturesGo Language Patterns This allows futures to be implemented in concurrent programming languages with support for channels, such as CSP and Go. The resulting futures are explicit, as they must be accessed by reading from the channel, rather than only evaluation. == See also == *Fiber (computer science) *Futex == References == == External links == *Concurrency patterns presentation given at scaleconf * Future Value and Promise Pipelining at the Portland Pattern Repository * Easy Threading with Futures in Python Category:Inter-process communication Category:Actor model (computer science) ",
    "title": "Futures and promises"
}