{
    "id": "302944",
    "text": "In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i.e. every finite linear combination of them is normally distributed. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space. A machine-learning algorithm that involves a Gaussian process uses lazy learning and a measure of the similarity between points (the kernel function) to predict the value for an unseen point from training data. The prediction is not just an estimate for that point, but also has uncertainty information\u2014it is a one-dimensional Gaussian distribution. For multi-output predictions, multivariate Gaussian processes are used, for which the multivariate Gaussian distribution is the marginal distribution at each point. For some kernel functions, matrix algebra can be used to calculate the predictions using the technique of kriging. When a parameterised kernel is used, optimisation software is typically used to fit a Gaussian process model. The concept of Gaussian processes is named after Carl Friedrich Gauss because it is based on the notion of the Gaussian distribution (normal distribution). Gaussian processes can be seen as an infinite-dimensional generalization of multivariate normal distributions. Gaussian processes are useful in statistical modelling, benefiting from properties inherited from the normal distribution. For example, if a random process is modelled as a Gaussian process, the distributions of various derived quantities can be obtained explicitly. Such quantities include the average value of the process over a range of times and the error in estimating the average using sample values at a small set of times. While exact models often scale poorly as the amount of data increases, multiple approximation methods have been developed which often retain good accuracy while drastically reducing computation time. ==Definition== A time continuous stochastic process \\left\\\\{X_t ; t\\in T\\right\\\\} is Gaussian if and only if for every finite set of indices t_1,\\ldots,t_k in the index set T : \\mathbf{X}_{t_1, \\ldots, t_k} = (X_{t_1}, \\ldots, X_{t_k}) is a multivariate Gaussian random variable. That is the same as saying every linear combination of (X_{t_1}, \\ldots, X_{t_k}) has a univariate normal (or Gaussian) distribution. Using characteristic functions of random variables, the Gaussian property can be formulated as follows: \\left\\\\{X_t ; t\\in T\\right\\\\} is Gaussian if and only if, for every finite set of indices t_1,\\ldots,t_k, there are real-valued \\sigma_{\\ell j}, \\mu_\\ell with \\sigma_{jj} > 0 such that the following equality holds for all s_1,s_2,\\ldots,s_k\\in\\mathbb{R} : \\operatorname{E}\\left(\\exp\\left(i \\ \\sum_{\\ell=1}^k s_\\ell \\ \\mathbf{X}_{t_\\ell}\\right)\\right) = \\exp \\left(-\\frac{1}{2} \\, \\sum_{\\ell, j} \\sigma_{\\ell j} s_\\ell s_j + i \\sum_\\ell \\mu_\\ell s_\\ell\\right). where i denotes the imaginary unit such that i^2 =-1. The numbers \\sigma_{\\ell j} and \\mu_\\ell can be shown to be the covariances and means of the variables in the process. ==Variance== The variance of a Gaussian process is finite at any time t, formally : \\operatorname{var}[X(t)] = \\operatorname{E}[|X(t)-\\operatorname{E}[X(t)]|^2] < \\infty \\quad \\text{for all } t \\in T. ==Stationarity== For general stochastic processes strict-sense stationarity implies wide-sense stationarity but not every wide-sense stationary stochastic process is strict-sense stationary. However, for a Gaussian stochastic process the two concepts are equivalent. A Gaussian stochastic process is strict-sense stationary if, and only if, it is wide- sense stationary. ==Example== There is an explicit representation for stationary Gaussian processes. A simple example of this representation is : X_t = \\cos(at) \\xi_1 + \\sin(at) \\xi_2 where \\xi_1 and \\xi_2 are independent random variables with the standard normal distribution. ==Covariance functions== A key fact of Gaussian processes is that they can be completely defined by their second-order statistics. Thus, if a Gaussian process is assumed to have mean zero, defining the covariance function completely defines the process' behaviour. Importantly the non-negative definiteness of this function enables its spectral decomposition using the Karhunen\u2013Lo\u00e8ve expansion. Basic aspects that can be defined through the covariance function are the process' stationarity, isotropy, smoothness and periodicity. Stationarity refers to the process' behaviour regarding the separation of any two points x and x'. If the process is stationary, it depends on their separation, x-x', while if non-stationary it depends on the actual position of the points x and x'. For example, the special case of an Ornstein\u2013Uhlenbeck process, a Brownian motion process, is stationary. If the process depends only on |x-x'|, the Euclidean distance (not the direction) between x and x', then the process is considered isotropic. A process that is concurrently stationary and isotropic is considered to be homogeneous; in practice these properties reflect the differences (or rather the lack of them) in the behaviour of the process given the location of the observer. Ultimately Gaussian processes translate as taking priors on functions and the smoothness of these priors can be induced by the covariance function. If we expect that for \"near-by\" input points x and x' their corresponding output points y and y' to be \"near-by\" also, then the assumption of continuity is present. If we wish to allow for significant displacement then we might choose a rougher covariance function. Extreme examples of the behaviour is the Ornstein-Uhlenbeck covariance function and the squared exponential where the former is never differentiable and the latter infinitely differentiable. Periodicity refers to inducing periodic patterns within the behaviour of the process. Formally, this is achieved by mapping the input x to a two dimensional vector u(x) = \\left( \\cos(x), \\sin(x) \\right). ===Usual covariance functions=== The effect of choosing different kernels on the prior function distribution of the Gaussian process. Left is a squared exponential kernel. Middle is Brownian. Right is quadratic. There are a number of common covariance functions: *Constant : K_\\operatorname{C}(x,x') = C *Linear: K_\\operatorname{L}(x,x') = x^T x' *white Gaussian noise: K_\\operatorname{GN}(x,x') = \\sigma^2 \\delta_{x,x'} *Squared exponential: K_\\operatorname{SE}(x,x') = \\exp \\Big(-\\frac{|d|^2}{2\\ell^2} \\Big) *Ornstein-Uhlenbeck: K_\\operatorname{OU}(x,x') = \\exp \\left(-\\frac{|d|} \\ell \\right) *Mat\u00e9rn: K_\\operatorname{Matern}(x,x') = \\frac{2^{1- u}}{\\Gamma( u)} \\Big(\\frac{\\sqrt{2 u}|d|}{\\ell} \\Big)^ u K_ u \\Big(\\frac{\\sqrt{2 u}|d|}{\\ell} \\Big) *Periodic: K_\\operatorname{P}(x,x') = \\exp\\left(-\\frac{ 2\\sin^2\\left(\\frac d 2 \\right)}{\\ell^2} \\right) *Rational quadratic: K_\\operatorname{RQ}(x,x') = (1+|d|^2)^{-\\alpha}, \\quad \\alpha \\geq 0 Here d = x- x'. The parameter \\ell is the characteristic length-scale of the process (practically, \"how close\" two points x and x' have to be to influence each other significantly), \\delta is the Kronecker delta and \\sigma the standard deviation of the noise fluctuations. Moreover, K_ u is the modified Bessel function of order u and \\Gamma( u) is the gamma function evaluated at u. Importantly, a complicated covariance function can be defined as a linear combination of other simpler covariance functions in order to incorporate different insights about the data-set at hand. Clearly, the inferential results are dependent on the values of the hyperparameters \\theta (e.g. \\ell and \\sigma) defining the model's behaviour. A popular choice for \\theta is to provide maximum a posteriori (MAP) estimates of it with some chosen prior. If the prior is very near uniform, this is the same as maximizing the marginal likelihood of the process; the marginalization being done over the observed process values y. This approach is also known as maximum likelihood II, evidence maximization, or empirical Bayes. ==Continuity== For a Gaussian process, continuity in probability is equivalent to mean-square continuity, and continuity with probability one is equivalent to sample continuity. The latter implies, but is not implied by, continuity in probability. Continuity in probability holds if and only if the mean and autocovariance are continuous functions. In contrast, sample continuity was challenging even for stationary Gaussian processes (as probably noted first by Andrey Kolmogorov), and more challenging for more general processes. As usual, by a sample continuous process one means a process that admits a sample continuous modification. ===Stationary case=== For a stationary Gaussian process X=(X_t)_{t\\in\\mathbb R}, some conditions on its spectrum are sufficient for sample continuity, but fail to be necessary. A necessary and sufficient condition, sometimes called Dudley-Fernique theorem, involves the function \\sigma defined by : \\sigma(h) = \\sqrt{ \\mathbb E \\big( X(t+h) - X(t) \\big)^2 } (the right-hand side does not depend on t due to stationarity). Continuity of X in probability is equivalent to continuity of \\sigma at 0. When convergence of \\sigma(h) to 0 (as h\\to 0) is too slow, sample continuity of X may fail. Convergence of the following integrals matters: : I(\\sigma) = \\int_0^1 \\frac{ \\sigma(h) }{ h \\sqrt{ \\log(1/h) } } \\, dh = \\int_0^\\infty 2\\sigma(\\mathbb e^{-x^2}) \\, dx , these two integrals being equal according to integration by substitution h = \\mathbb e^{-x^2}, \\textstyle x = \\sqrt{\\log(1/h)} . The first integrand need not be bounded as h\\to 0+, thus the integral may converge (I(\\sigma)<\\infty) or diverge (I(\\sigma)=\\infty). Taking for example \\sigma(\\mathbb e^{-x^2})=\\tfrac1{x^a} for large x, that is, \\sigma(h)=(\\log(1/h))^{-a/2} for small h, one obtains I(\\sigma)<\\infty when a>1, and I(\\sigma)=\\infty when 0 In these two cases the function \\sigma is increasing on [0,\\infty), but generally it is not. Moreover, the condition : (*) there exists \\varepsilon>0 such that \\sigma is monotone on [0,\\varepsilon] does not follow from continuity of \\sigma and the evident relations \\sigma(h)\\ge0 (for all h) and \\sigma(0)=0. Theorem 1. Let \\sigma be continuous and satisfy (*). Then the condition I(\\sigma)<\\infty is necessary and sufficient for sample continuity of X. Some history. Sufficiency was announced by Xavier Fernique in 1964, but the first proof was published by Richard M. Dudley in 1967. Necessity was proved by Michael B. Marcus and Lawrence Shepp in 1970. There exist sample continuous processes X such that I(\\sigma)=\\infty; they violate condition (*). An example found by Marcus and Shepp is a random lacunary Fourier series : X_t = \\sum_{n=1}^\\infty c_n ( \\xi_n \\cos \\lambda_n t + \\eta_n \\sin \\lambda_n t ) , where \\xi_1,\\eta_1,\\xi_2,\\eta_2,\\dots are independent random variables with standard normal distribution; frequencies 0<\\lambda_1<\\lambda_2<\\dots are a fast growing sequence; and coefficients c_n>0 satisfy \\textstyle \\sum_n c_n < \\infty. The latter relation implies \\textstyle\\mathbb E \\sum_n c_n ( |\\xi_n| + |\\eta_n| ) = \\sum_n c_n \\mathbb E ( |\\xi_n| + |\\eta_n| ) = \\text{const} \\cdot \\sum_n c_n < \\infty, whence \\sum_n c_n ( |\\xi_n| + |\\eta_n| ) < \\infty almost surely, which ensures uniform convergence of the Fourier series almost surely, and sample continuity of X. Autocorrelation of a random lacunary Fourier series Its autocovariation function : \\mathbb E X_t X_{t+h} = \\sum_{n=1}^\\infty c_n^2 \\cos \\lambda_n h is nowhere monotone (see the picture), as well as the corresponding function \\sigma, : \\sigma(h) = \\sqrt{ 2 \\mathbb E X_t X_t - 2 \\mathbb E X_t X_{t+h} } = 2 \\sqrt{ \\sum_{n=1}^\\infty c_n^2 \\sin^2 \\frac{\\lambda_n h}2 } . ==Brownian motion as the integral of Gaussian processes== A Wiener process (aka Brownian motion) is the integral of a white noise generalized Gaussian process. It is not stationary, but it has stationary increments. The Ornstein\u2013Uhlenbeck process is a stationary Gaussian process. The Brownian bridge is (like the Ornstein\u2013Uhlenbeck process) an example of a Gaussian process whose increments are not independent. The fractional Brownian motion is a Gaussian process whose covariance function is a generalisation of that of the Wiener process. ==Driscoll's zero-one law== Driscoll's zero-one law is a result characterizing the sample functions generated by a Gaussian process. Let f be a mean-zero Gaussian process \\left\\\\{X_t ; t\\in T\\right\\\\} with non-negative definite covariance function K. Let \\mathcal{H}(R) be a Reproducing kernel Hilbert space with positive definite kernel R. Then :\\lim_{n\\to\\infty} \\operatorname{tr}[K_nR_n^{-1}] < \\infty, where K_n and R_n are the covariance matrices of all possible pairs of n points, implies :\\Pr[f \\in \\mathcal{H}(R)] = 1. What's more, :\\lim_{n\\to\\infty} \\operatorname{tr}[K_nR_n^{-1}] = \\infty implies :\\Pr[f \\in \\mathcal{H}(R)] = 0. This has significant implications when K = R, as :\\lim_{n\\to\\infty} \\operatorname{tr}[R_nR_n^{-1}] = \\lim_{n\\to\\infty}\\operatorname{tr}[I] = \\lim_{n\\to\\infty} n = \\infty. As such, almost all sample paths of a mean-zero Gaussian process with positive definite kernel K will lie outside of the Hilbert space \\mathcal{H}(K). ==Linearly constrained Gaussian processes== For many applications of interest some pre- existing knowledge about the system at hand is already given. Consider e.g. the case where the output of the Gaussian process corresponds to a magnetic field; here, the real magnetic field is bound by Maxwell\u2019s equations and a way to incorporate this constraint into the Gaussian process formalism would be desirable as this would likely improve the accuracy of the algorithm. A method on how to incorporate linear constraints into Gaussian processes already exists: Consider the (vector valued) output function f(x) which is known to obey the linear constraint (i.e. \\mathcal{F}_X is a linear operator) :\\mathcal{F}_X(f(x)) = 0. Then the constraint \\mathcal{F}_X can be fulfilled by choosing f(x) = \\mathcal{G}_X(g(x)), where g(x) \\sim \\mathcal{GP}(\\mu_g, K_g) is modelled as a Gaussian process, and finding \\mathcal{G}_X s.t. :\\mathcal{F}_X(\\mathcal{G}_X(g)) = 0 \\qquad \\forall g. Given \\mathcal{G}_X and using the fact that Gaussian processes are closed under linear transformations, the Gaussian process for f obeying constraint \\mathcal{F}_X becomes :f(x) = \\mathcal{G}_X g \\sim \\mathcal{GP} ( \\mathcal{G}_X \\mu_g, \\mathcal{G}_X K_g \\mathcal{G}_{X'}^T ). Hence, linear constraints can be encoded into the mean and covariance function of a Gaussian process. ==Applications== An example of Gaussian Process Regression (prediction) compared with other regression models.The documentation for scikit-learn also has similar examples. A Gaussian process can be used as a prior probability distribution over functions in Bayesian inference. Given any set of N points in the desired domain of your functions, take a multivariate Gaussian whose covariance matrix parameter is the Gram matrix of your N points with some desired kernel, and sample from that Gaussian. For solution of the multi- output prediction problem, Gaussian process regression for vector-valued function was developed. In this method, a 'big' covariance is constructed, which describes the correlations between all the input and output variables taken in N points in the desired domain. This approach was elaborated in detail for the matrix-valued Gaussian processes and generalised to processes with 'heavier tails' like Student-t processes. Inference of continuous values with a Gaussian process prior is known as Gaussian process regression, or kriging; extending Gaussian process regression to multiple target variables is known as cokriging. Gaussian processes are thus useful as a powerful non- linear multivariate interpolation tool. Gaussian process regression can be further extended to address learning tasks in both supervised (e.g. probabilistic classification) and unsupervised (e.g. manifold learning) learning frameworks. Gaussian processes can also be used in the context of mixture of experts models, for example. The underlying rationale of such a learning framework consists in the assumption that a given mapping cannot be well captured by a single Gaussian process model. Instead, the observation space is divided into subsets, each of which is characterized by a different mapping function; each of these is learned via a different Gaussian process component in the postulated mixture. ===Gaussian process prediction, or Kriging=== Gaussian Process Regression (prediction) with a squared exponential kernel. Left plot are draws from the prior function distribution. Middle are draws from the posterior. Right is mean prediction with one standard deviation shaded. When concerned with a general Gaussian process regression problem (Kriging), it is assumed that for a Gaussian process f observed at coordinates x, the vector of values is just one sample from a multivariate Gaussian distribution of dimension equal to number of observed coordinates . Therefore, under the assumption of a zero-mean distribution, , where is the covariance matrix between all possible pairs for a given set of hyperparameters \u03b8. As such the log marginal likelihood is: : \\log p(f(x)\\mid\\theta,x) = -\\frac{1}{2}f(x)^T K(\\theta,x,x')^{-1} f(x') -\\frac 1 2 \\log \\det(K(\\theta,x,x')) - \\frac{n} 2 \\log 2\\pi and maximizing this marginal likelihood towards \u03b8 provides the complete specification of the Gaussian process f. One can briefly note at this point that the first term corresponds to a penalty term for a model's failure to fit observed values and the second term to a penalty term that increases proportionally to a model's complexity. Having specified \u03b8 making predictions about unobserved values at coordinates x* is then only a matter of drawing samples from the predictive distribution p(y^*\\mid x^*,f(x),x) = N(y^*\\mid A,B) where the posterior mean estimate A is defined as :A = K(\\theta,x^*,x) K(\\theta,x,x')^{-1} f(x) and the posterior variance estimate B is defined as: :B = K(\\theta,x^*,x^*) - K(\\theta,x^*,x) K(\\theta,x,x')^{-1} K(\\theta,x^*,x)^T where is the covariance between the new coordinate of estimation x* and all other observed coordinates x for a given hyperparameter vector \u03b8, and are defined as before and is the variance at point x* as dictated by \u03b8. It is important to note that practically the posterior mean estimate (the \"point estimate\") is just a linear combination of the observations ; in a similar manner the variance of is actually independent of the observations . A known bottleneck in Gaussian process prediction is that the computational complexity of inference and likelihood evaluation is cubic in the number of points |x|, and as such can become unfeasible for larger data sets. Works on sparse Gaussian processes, that usually are based on the idea of building a representative set for the given process f, try to circumvent this issue. === Bayesian neural networks as Gaussian processes === Bayesian neural networks are a particular type of Bayesian network that results from treating deep learning and artificial neural network models probabilistically, and assigning a prior distribution to their parameters. Computation in artificial neural networks is usually organized into sequential layers of artificial neurons. The number of neurons in a layer is called the layer width. As layer width grows large, many Bayesian neural networks reduce to a Gaussian process with a closed form compositional kernel. This Gaussian process is called the Neural Network Gaussian Process (NNGP). It allows predictions from Bayesian neural networks to be more efficiently evaluated, and provides an analytic tool to understand deep learning models. == Computational issues == In practical applications, Gaussian process models are often evaluated on a grid leading to multivariate normal distributions. Using these models for prediction or parameter estimation using maximum likelihood requires evaluating a multivariate Gaussian density, which involves calculating the determinant and the inverse of the covariance matrix. Both of these operations have cubic computational complexity which means that even for grids of modest sizes, both operations can have a prohibitive computational cost. This drawback led to the development of multiple approximation methods. ==See also== * Bayes linear statistics * Bayesian interpretation of regularization * Kriging * Gaussian free field * Gauss\u2013Markov process * Gradient-enhanced kriging (GEK) * Student's t-process == References == ==External links== * The Gaussian Processes Web Site, including the text of Rasmussen and Williams' Gaussian Processes for Machine Learning * A gentle introduction to Gaussian processes * A Review of Gaussian Random Fields and Correlation Functions * Efficient Reinforcement Learning using Gaussian Processes ===Software=== * GPML: A comprehensive Matlab toolbox for GP regression and classification * STK: a Small (Matlab/Octave) Toolbox for Kriging and GP modeling * Kriging module in UQLab framework (Matlab) * Matlab/Octave function for stationary Gaussian fields * Yelp MOE \u2013 A black box optimization engine using Gaussian process learning * ooDACE \u2013 A flexible object-oriented Kriging Matlab toolbox. * GPstuff \u2013 Gaussian process toolbox for Matlab and Octave * GPy \u2013 A Gaussian processes framework in Python * GSTools - A geostatistical toolbox, including Gaussian process regression, written in Python * Interactive Gaussian process regression demo * Basic Gaussian process library written in C++11 * scikit-learn \u2013 A machine learning library for Python which includes Gaussian process regression and classification * - The Kriging toolKit (KriKit) is developed at the Institute of Bio- and Geosciences 1 (IBG-1) of Forschungszentrum J\u00fclich (FZJ) ===Video tutorials=== * Gaussian Process Basics by David MacKay * Learning with Gaussian Processes by Carl Edward Rasmussen * Bayesian inference and Gaussian processes by Carl Edward Rasmussen Category:Stochastic processes Category:Kernel methods for machine learning Category:Nonparametric Bayesian statistics Category:Normal distribution ",
    "title": "Gaussian process"
}