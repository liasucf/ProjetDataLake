{
    "id": "46221886",
    "text": "The MotionParallax3D displays are a class of virtual reality devices that create the illusion of volumetric objects by displaying a projection of a virtual object generated to match the viewer's position relative to the screen. == Principles == The general principal of making a projection with MotionParallax3D displays The image of the object the user sees The projection of a virtual object displayed on the screen MotionParallax3D displays contain one or more flat or curved screens. These screens have different sizes, shapes, and mutual disposition depending on the form factor of the device. The projections of virtual objects are formed so that the virtual image the user sees looks exactly the same as the image that would be seen if the virtual object actually existed. In order to display the correct projections of virtual objects, the virtual reality system requires the current coordinates of the observer's eyes. In contrast with stereo displays involving only binocular vision, the MotionParallax3D displays utilize one of the most important principles of human spatial perception\u2014motion parallax. Motion parallax is a displacement of the parts of the image relative to each other with the angular velocity proportional to the distance difference between the parts of the image and a viewer when the relative position of the viewer and the observed object changes. The MotionParallax3D displays use this mechanism of perceiving volume by constantly changing the image displayed based on the current coordinates of the user's eyes. Due to this, the virtual objects are shifted relative to each other and relative to the visible real objects according to the laws and principles applying to the real world's objects. It allows the brain to build the a holistic view of the world containing both real and virtual objects with indistinguishable behavior. Most MotionParallax3D displays are based on stereo displays and display separate images to the left and right eyes. This gives a substantial advantage in building a complete system of virtual reality, but is not necessary for the perception of volume since the motion parallax mechanism alone is enough for the brain to perceive virtual objects as having a definite shape, volume, and a distance from the user's eyes. == Tracking systems == To make the image projection display correctly, the system requires up-to-date and exact coordinates of the user's eyes. The MotionParallax3D displays get these coordinates from the head-tracking systems. The tracking systems for MotionParallax3D displays can be based on different principles: * Optical: ** Based on active markers (NettleBox) ** Based on passive markers (EON ICube) ** Based on face, eye, head contour etc. recognition (Amazon Fire Phone) * Ultrasonic (RUCAP UM-5) * Electromagnetic * Mechanical * Mixed, combining several tracking mechanisms e.g. using gyroscopes and accelerometers in addition to optical markers. == Quality indicators == The quality of MotionParallax3D displays, which is mostly based on how realistically a virtual image can be displayed, is determined by a combination of three main characteristics: * Stereoscopic separation quality (if it is done) * Rendering quality * Geometric accuracy of the projection. Stereoscopic separation quality decreases due to ghosting \u2013 a phenomenon where each eye, in addition to the image intended for it, perceives the image intended for the other eye. Ghosting can be caused by different factors, e.g. luminophore afterglow in plasma screens or the incomplete matching of the polarization direction during polarization stereoscopic separation. Rendering quality is generally not a problem for modern MotionParallax3D displays, however, the high detalization of rendering and the use of special effects allow psychological mechanisms for volume perception such as texture gradient, shading, etc. and they help increase the reality of the perception. The geometric accuracy of the projection of 3D-scenes is the most important indicator of MotionParallax3D display quality. It is influenced by the accuracy of the head-tracking and the interval between the moment when the tracking starts and the moment when the image is displayed. Tracking accuracy affects the accuracy of the projection. The architecture and geometry of the tracking devices, quality of calibration, and the integrated value of inaccuracy, which is affected by noise, can all contribute to a reduction in projection correctness. The interval between when the user's head-tracking starts, and when the image is displayed, is the primary cause of geometric incorrectness of 3D-scenes projection in MotionParallax3D systems. Latency occurs because operations such as head- tracking, rendering and displaying the projection require time. Modern MotionParallax3D displays use head-tracking forecast technology that compensates for the delay partially, but the accuracy and the forecast horizon are highly dependent on the quality of the initial data (accuracy) and also the quantity of the datasets with the user's position coordinates that the system receives per time unit. The peculiarity of visual perception is that the brain interprets the latency of virtual object images not as latency but as a distortion of the geometry of virtual objects. In this case, the dissonance between the information the user receives from the visual perception and the vestibular apparatus can cause symptoms of virtual reality sickness which include nausea, headache, and ophthalmalgia (eye pain). Higher quality MotionParallax3D displays reduce the chances of these symptoms occurring. However, even in case of a perfect MotionParallax3D display, the symptoms of cybersickness can occur in susceptible individuals due to the dissonance of the focusing and convergence visual mechanisms; if a virtual object is located at a considerable distance from the surface on which the projected image is displayed, an attempt to fix the eyes and focus on the nearby virtual objects can lead to the opposite result. == The Place of MotionParallax3D displays among VR systems == NettleBox virtual reality display Currently all widely used computer virtual reality devices can be divided into two classes: * MotionParallax3D displays * HMD (head-mounted display) displays. In addition to these two classes there are other more exotic variants: e.g. the CastAR system, under development, in which the projection of the correct image onto a surface is achieved by placing the projectors directly on the glasses. However such devices are not so widespread at the moment and exist only as prototypes. Head-mounted displays usually isolate users from the real world, whereas MotionParallax3D displays allow users to keep their orientation in the environment. This also imposes restrictions on MotionParallax3D displays; since the user sees both real and virtual objects, it is necessary to make their behavior identical which is achieved by reducing latency to an acceptable level (no more than 20 ms). == Implementations == Because MotionParallax3D displays are a tracking system connected to devices that form and display the images, there are a lot of form factors with disparities in size: from the smartphones to the virtual reality rooms to full immersion systems. Below are the most common representatives of each class. EON ICube Mobile CAVE Crayoland Amazon Fire Phone *Stereo 3D: not present *Tracking system : optical, tracking of the user's eyes position The ZSpace virtual reality system * Stereo 3D: passive stereo * Tracking system: optical, tracking of passive markers The NettleBox virtual reality system * Stereo 3D: Active 3D * Tracking system: optical, tracking of active markers EON ICube CAVE * Stereo 3D: Active 3D * Tracking system: optical, tracking of the passive markers position == See also == * Augmented reality * Cave automatic virtual environment * Depth perception * Head-mounted display * Motion capture * Virtual reality * Virtual reality sickness == References == MotionParallax3D Technology Category:Virtual reality ",
    "title": "MotionParallax3D"
}